---
title: ""
author: Till Grallert
date: 2017-05-25 14:00:13 +0200
duration: 30
tags:
- presentation
---

# 1. Introduction
## research questions

- What did they read in late-Ottoman Damascus?
- Who published in late-Ottoman Damascus?

## sources

- Muḥammad Kurd ʿAlī's monthly journal *al-Muqtabas*
- ʿAbd al-Qādir al-Iskandarānī's monthly journal *al-Ḥaqāʾiq*

## possible methodologies

1. manual compilation of works, authors, places
    - read and excerpt some 8000 pages
2. machine-guided analysis


# 2. Preliminary results
## publication places of reviewed / referenced works

<script src="https://embed.github.com/view/geojson/OpenArabicPE/slides/gh-pages/assets/maps/muqtabas_reviews-toponyms.geojson?height=300&width=800"></script>

## publication places of reviewed / referenced works

<iframe src="../assets/maps/map_muqtabas-reviews.html"></iframe>

<!-- # Who published in late-Ottoman Damascus? -->
## locations in bylines

<script src="https://embed.github.com/view/geojson/OpenArabicPE/slides/gh-pages/assets/maps/muqtabas_bylines-toponyms.geojson?height=300&width=800"></script>

## locations in bylines

<iframe src="../assets/maps/map_muqtabas-bylines.html"></iframe>

## authors in bylines

<iframe src="../assets/muqtabas_word-cloud.html" style="width: 80%; height: 80%;"></iframe>

# How to get there?
## Workflow

1. Digital edition
2. Clean your data
3. Analyse yuor data

## Workflow 1: digital edition

1. Get a digital text
2. Model the digital text in TEI: -> XML files
3. Mark-up and disambiguation of entities (persons, places, works, dates)

## Problems 1: digital edition

1. conceptual (quasi) standards such as the TEI
    - <!-- available mark-up schemes despite being language agnostic are -->  rooted in the Western episteme
2. technical standards and tools such XML, XPath etc.
    - formally language/script agnostic but rooted in the Western episteme
    - based on Latin scripts

<!-- examples for both cases from other talks -->

## Workflow 2: cleaning the data

- normalization: 
    + unify spelling
    - machine-actionable Gregorian dates
- disambiguation
- Geocode toponyms

## Problems 2: normalization

1. Normalization
    - XPath officially supports *hijrī* dates, but the specification was never implemented
    - all calendars must be normalized with custom code!
2. Disambiguation: Authority files and linke open data (LOD) such as VIAF, GND, GeoNames etc.
    - Western data models
    - many non-Western entities have no entries
    - entries might only be available in transcription
    - automatic matching generates false positives

## Workflow 3: analysis

1. Extract bibliographic metadata on the basis of the TEI model as MODS: -> XML files
4. Analyse bibliographic data for patterns
5. Visualise / map patterns